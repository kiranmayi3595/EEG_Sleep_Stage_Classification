# -*- coding: utf-8 -*-
"""Sleep_Stage_Classification_RandomForestClassifier

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZvXr798jRFwkJtYmCCKhJvXNJN1riw2j

# **Sleep Stage Classification from PSG Data**

This project performs a supervised multiclass classification of sleep stages using EEG data from the Sleep Physionet dataset. We aim to predict the sleep stage of one subject (Bob) using a model trained on another subject (Alice).

Each 30-second segment of EEG data is labeled as one of five standard sleep stages:

1. W (Wake)
2. N1 (Light Sleep)
3. N2 (Intermediate Sleep)
4. N3 (Deep Sleep)
5. REM (Rapid Eye Movement Sleep)


We preprocess EEG signals, extract features, train a classifier on Alice’s data, and evaluate its performance on Bob’s data to assess how well sleep staging generalizes across individuals.

This tutorial is adapted from the MNE-Python sleep classification example [1](https://ieeexplore.ieee.org/document/8307462)
"""

# @title
!pip install mne

"""Purpose - Library Used

EEG data loading - mne, fetch_data

Preprocessing	   - FunctionTransformer, mne

Model training   - RandomForestClassifier

Evaluation.      - accuracy_score, confusion_matrix,

Visualization	   - matplotlib, numpy

"""

# @title
import matplotlib.pyplot as plt
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import FunctionTransformer

import mne
from mne.datasets.sleep_physionet.age import fetch_data

"""## 📥 Load and Visualize Sleep EEG Data

We use `mne.datasets.sleep_physionet.age.fetch_data()` to download sleep EEG (PSG) and hypnogram data for two subjects ("Candice" and "Drake") from the **Sleep Physionet** dataset. We then create an MNE `Raw` object from the PSG recording and attach the expert-provided sleep stage annotations (hypnogram). This allows us to visualize the raw EEG and prepare for event-based epoching.

"""

# @title
CANDICE, DRAKE = 2, 3

#Fetches PSG.edf (raw data) and Hypnogram.edf (Sleep stage annotations time-matched to PSG)
[candice_files, drake_files] = fetch_data(subjects=[CANDICE, DRAKE], recording=[1]) #Fetches data from night 2

#Training data
raw_train = mne.io.read_raw_edf(
    candice_files[0],
    stim_channel="Event marker",
    infer_types=True,
    preload=True,
    verbose="error",  # ignore issues with stored filter settings
)

#Read and Assign annotations to training data
annot_train = mne.read_annotations(candice_files[1])
raw_train.set_annotations(annot_train, emit_warning=False)

# @title
# plot some data
# scalings were chosen manually to allow for simultaneous visualization of
# different channel types in this specific dataset
raw_train.plot(
    start=60,
    duration=60,
    scalings=dict(eeg=1.5*1e-4, resp=1e3, eog=1e-4, emg=1e-7, misc=1e-1),
);

"""## 💤 Extracting Sleep Stage Events (30s Segments)

We map raw sleep stage annotations (W, 1, 2, 3, 4, R) into 5 categories by merging stages 3 & 4 into one "deep sleep" class. To reduce class imbalance, we crop out long wake periods before and after sleep, keeping only 30 minutes of wake on either side.

Then, we extract 30-second event-based epochs labeled by sleep stage using `mne.events_from_annotations()` and visualize the result as a timeline of sleep stages.

This prepares our data for classification, with one label per 30s chunk.
"""

annotation_desc_2_event_id = {
    "Sleep stage W": 1,
    "Sleep stage 1": 2,
    "Sleep stage 2": 3,
    "Sleep stage 3": 4,
    "Sleep stage 4": 4,
    "Sleep stage R": 5,
}

# keep last 30-min wake events before sleep and first 30-min wake events after
# sleep and redefine annotations on raw data
annot_train.crop(annot_train[1]["onset"] - 30 * 60, annot_train[-2]["onset"] + 30 * 60)
raw_train.set_annotations(annot_train, emit_warning=False)

events_train, _ = mne.events_from_annotations(
    raw_train, event_id=annotation_desc_2_event_id, chunk_duration=30.0
)

# create a new event_id that unifies stages 3 and 4
event_id = {
    "Sleep stage W": 1,
    "Sleep stage 1": 2,
    "Sleep stage 2": 3,
    "Sleep stage 3/4": 4,
    "Sleep stage R": 5,
}

"""## 🧠 Visualizing 30s Raw EEG Segments for Each Sleep Stage

We use Candice's PSG data and expert-provided annotations to extract one 30-second segment per sleep stage (Wake, N1, N2, N3/4, REM). Each segment is visualized to understand how brain signals differ across stages. This step helps build intuition for what spectral and morphological features characterize each stage.
"""

# Reverse mapping to label sleep stages
event_id_to_stage = {
    1: "Wake",
    2: "N1",
    3: "N2",
    4: "N3/4",
    5: "REM"
}

# Map to store one example 30s segment per stage
examples = {}

# Loop through annotations and collect one 30s example per stage
for annot in annot_train:
    label = annot["description"]
    if label in annotation_desc_2_event_id:
        stage_id = annotation_desc_2_event_id[label]
        stage_name = event_id_to_stage[stage_id]
        if stage_name not in examples:
            start = annot["onset"]
            examples[stage_name] = (start, start + 30)

# Custom scaling for raw EEG plot
custom_scalings = dict(
    eeg=1.5 * 1e-4,
    resp=1e3,
    eog=1e-4,
    emg=1e-7,
    misc=1e-1
)

# Plot each sleep stage's 30s EEG segment with specified scaling
for stage, (start, stop) in examples.items():
    print(f"Plotting stage {stage} from {start:.1f}s to {stop:.1f}s")
    raw_train.plot(
        start=start,
        duration=30,
        picks="data",  # includes EEG, EOG, EMG, etc.
        title=f"Candice – Stage: {stage}",
        scalings=custom_scalings,
        show=True
    )

# plot events
fig = mne.viz.plot_events(
    events_train,
    event_id=event_id,
    sfreq=raw_train.info["sfreq"],
    first_samp=events_train[0, 0],
)

# keep the color-code for further plotting
stage_colors = plt.rcParams["axes.prop_cycle"].by_key()["color"]

"""## ⏱️ Convert Continuous EEG to 30-second Epochs"""

#To adjust for floating point precision in epoch intervals
tmax = 30.0 - 1.0 / raw_train.info["sfreq"]  # tmax in included

#Epochs object
epochs_train = mne.Epochs(
    raw=raw_train,
    events=events_train,
    event_id=event_id,
    tmin=0.0,
    tmax=tmax,
    baseline=None,
)
del raw_train

print(epochs_train)

"""# Applying the same steps to the test data from Drake

"""

raw_test = mne.io.read_raw_edf(
    drake_files[0],
    stim_channel="Event marker",
    infer_types=True,
    preload=True,
    verbose="error",
)
annot_test = mne.read_annotations(drake_files[1])
annot_test.crop(annot_test[1]["onset"] - 30 * 60, annot_test[-2]["onset"] + 30 * 60)
raw_test.set_annotations(annot_test, emit_warning=False)
events_test, _ = mne.events_from_annotations(
    raw_test, event_id=annotation_desc_2_event_id, chunk_duration=30.0
)
epochs_test = mne.Epochs(
    raw=raw_test,
    events=events_test,
    event_id=event_id,
    tmin=0.0,
    tmax=tmax,
    baseline=None,
)
del raw_test

print(epochs_test)

"""## 📊 Visualizing Power Spectral Density (PSD) by Sleep Stage

To explore how different sleep stages vary in brain activity, we compute and plot the Power Spectral Density (PSD) for each stage in Alice and Bob's EEG data.

We observe that certain stages (e.g., N3/4) show stronger delta power, while others (like Wake or REM) emphasize higher frequencies. These consistent spectral patterns suggest that frequency-based features are useful for classification.

"""

# visualize Candice vs. Drake PSD by sleep stage.
fig, (ax1, ax2) = plt.subplots(ncols=2)

# iterate over the subjects
stages = sorted(event_id.keys());
for ax, title, epochs in zip([ax1, ax2], ["Candice", "Drake"], [epochs_train, epochs_test]):
    for stage, color in zip(stages, stage_colors):
        spectrum = epochs[stage].compute_psd(fmin=0.1, fmax=20.0)
        spectrum.plot(
            ci=None,
            color=color,
            axes=ax,
            show=False,
            average=True,
            amplitude=False,
            spatial_colors=False,
            picks="data",
            exclude="bads",
        );
    ax.set(title=title, xlabel="Frequency (Hz)")
ax1.set(ylabel="µV²/Hz (dB)")
ax2.legend(ax2.lines[2::3], stages)

"""# Feature Extraction
Function to extract EEG features based on relative power in specific frequency bands (delta, theta, alpha, beta gamma) to be able to predict sleep stages from EEG signals.

Function returns 2D array with average relative EEG power of shape [n_epochs,5 x n_channels]

"""

def eeg_power_band(epochs):
    """EEG relative power band feature extraction.

    This function takes an ``mne.Epochs`` object and creates EEG features based
    on relative power in specific frequency bands that are compatible with
    scikit-learn.

    Parameters
    ----------
    epochs : Epochs
        The data.

    Returns
    -------
    X : numpy array of shape [n_samples, 5 * n_channels]
        Transformed data.
    """
    # specific frequency bands
    FREQ_BANDS = {
        "delta": [0.5, 4.5],
        "theta": [4.5, 8.5],
        "alpha": [8.5, 11.5],
        "sigma": [11.5, 15.5],
        "beta": [15.5, 30],
    }

    spectrum = epochs.compute_psd(picks="eeg", fmin=0.5, fmax=30.0)
    psds, freqs = spectrum.get_data(return_freqs=True)
    # Normalize the PSDs
    psds /= np.sum(psds, axis=-1, keepdims=True)

    X = []
    for fmin, fmax in FREQ_BANDS.values():
        psds_band = psds[:, :, (freqs >= fmin) & (freqs < fmax)].mean(axis=-1)
        X.append(psds_band.reshape(len(psds), -1))

    return np.concatenate(X, axis=1)

"""## 🔄 Multiclass Classification of Sleep Stages Using Scikit-learn Pipeline

In this section, we build a sleep stage classifier using a scikit-learn `Pipeline`. Our goal is to train a model on Candice’s EEG data and test how well it can predict sleep stages for another subject (e.g., Drake).

We use two key scikit-learn tools:

- **FunctionTransformer**: Wraps our custom `eeg_power_band()` function to convert EEG epochs into relative power features from standard frequency bands (delta, theta, alpha, sigma, beta).
- **Pipeline**: Chains the feature extraction and classification steps into a single model that can be trained and tested easily.

The pipeline takes raw MNE `Epochs` as input, extracts features automatically, and fits a `RandomForestClassifier` to predict one of five sleep stages (Wake, N1, N2, N3/4, REM).

Finally, we evaluate performance by comparing the predicted sleep stages with the actual annotated stages using `accuracy_score`.
"""

pipe = make_pipeline(
    FunctionTransformer(eeg_power_band, validate=False),
    RandomForestClassifier(n_estimators=100, random_state=42),
)

# Train
y_train = epochs_train.events[:, 2]
pipe.fit(epochs_train, y_train)

# Test
y_pred = pipe.predict(epochs_test)

# Assess the results
y_test = epochs_test.events[:, 2]
acc = accuracy_score(y_test, y_pred)

print(f"Accuracy score: {acc}")

"""## 📊 Model Evaluation - Confusion Matrix and Classification Report

To better understand how well our classifier performs across different sleep stages, we go beyond overall accuracy and compute two detailed evaluation metrics:

- **Confusion Matrix**: Shows how often each sleep stage was correctly predicted vs. confused with another stage. Each row represents the true class, and each column represents the predicted class.
- **Classification Report**: Provides precision, recall, F1-score, and support (number of true samples) for each sleep stage. These metrics help us assess the model's strengths and weaknesses across all classes.
"""

print(confusion_matrix(y_test, y_pred))

print(classification_report(y_test,y_pred,target_names=event_id.keys()))

"""## 🧠 Evaluation Summary

After training the model on Candice’s data, we evaluated it on Drake’s sleep EEG data. The classification report provides insight into how well the model predicts each sleep stage.

### Key Observations:

- **Stage 2 (N2)** had the strongest performance, with high precision (0.84) and recall (0.92), reflecting the model's ability to correctly identify this stage.
- **REM** sleep was also predicted fairly well, with an F1-score of 0.72.
- **Wake** stages had perfect precision (1.00), but only moderate recall (0.59), meaning the model never falsely predicts "Wake", but misses some real wake segments.
- **Stage 1 (N1)** had poor performance, especially in precision (0.21), likely due to its overlap with other stages like N2 and REM.
- **Stage 3/4** showed extremely low recall (0.05), suggesting the model struggles to detect deep sleep reliably.

### Final Accuracy: **74%**

This level of performance is strong for a 5-class EEG-based sleep stage classifier using only spectral power features from EEG signals.

### Next Steps:

- Improve N1 and N3/4 detection using more features (e.g., time-domain features, spindles, entropy).
- Use class balancing techniques or better sampling to address class imbalance.
- Visualize misclassified epochs for model introspection.
"""